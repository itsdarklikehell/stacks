services:
  ollama:
    image: ${IMAGE:-ollama/ollama}
    container_name: ${NAME:-ollama}
    restart: ${RESTART:-unless-stopped}

    labels:
      - autoheal-app=true
      - keep_healthy
      - "com.centurylinklabs.watchtower.enable=true"

    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - OLLAMA_KEEP_ALIVE=24h
      - ENABLE_IMAGE_GENERATION=True
      - COMFYUI_BASE_URL=http://comfyui:7860
      - OLLAMA_MODELS=/root/.ollama/models

    volumes:
      - ollama-data:/root/.ollama
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - ../DATA/ollama:/root/.ollama

    hostname: ${NAME:-ollama}

    # networks:
    #   - ai-services
    #   - host

    ports:
      - ${OLLAMA_PORT:-11434}:11434

    env_file:
      - .env.ollama

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]


  ollama-assistant:
    image: node:18
    volumes:
      - ../DATA/ollama/assistant:/app
    working_dir: /app
    depends_on:
      - ollama
    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - OLLAMA_KEEP_ALIVE=24h
      - ENABLE_IMAGE_GENERATION=True
      - COMFYUI_BASE_URL=http://comfyui:7860
      - OLLAMA_MODELS=/root/.ollama/models