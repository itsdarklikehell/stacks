services:
  whisperX:
    image: ${IMAGE:-ghcr.io/jim60105/whisperx:latest}
    # pull_policy: always
    container_name: ${NAME:-whishperX}
    restart: ${RESTART:-unless-stopped}

    user: ${PUID:-1000}:${PGID:-1000}

    build:
      context: ../../DATA/ai-stack/whisperX
      args:
        UID: ${PUID:-1000}
        GID: ${PGID:-1000}
        LANG: en # en, nl, de
        WHISPER_MODEL: base # tiny, base, distil-large-v3, large-v3 no_model
      # target: whisperx:base-en # whisperx:base-en, whisperx:large-v3-ja, whisperx:ubi-no_model
      dockerfile: ./Dockerfile

    command:
      [--, --model, large-v3, --language, en, --output_format, srt, audio.mp3]

    labels:
      - com.centurylinklabs.watchtower.enable=true
      # - autoheal-app
      # - autoheal-app=true

    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - TZ=${TZ:-Europe/Amsterdam}
      # - PORT=${PORT:-8082}

    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - whisper_cache:/.cache
      - ../../DATA/ai-stack/whisperX:/app

    hostname: ${NAME:-whisperX}

    networks:
      host:
      ai-services:

    # ports:
    #   - ${PORT:-8082}:80

    env_file:
      - ./whisperx/.env

    # depends_on:
    #   - mongo-whispher
    #   - libretranslate-whispher

    runtime: nvidia
    deploy:
      replicas: 1
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    tty: true

    stdin_open: true

    # healthcheck:
    # test:
    #   [
    #     CMD,
    #     wget,
    #     --no-verbose,
    #     --tries=3,
    #     --spider,
    #     http://localhost:${PORT:-8082}/api/health,
    #   ]
    #   interval: 30s
    #   timeout: 10s
    #   start_period: 30s
    #   retries: 3

    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: 3
