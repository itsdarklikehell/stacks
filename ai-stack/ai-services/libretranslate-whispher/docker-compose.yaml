services:
  libretranslate-whispher:
    image: "${IMAGE:-libretranslate/libretranslate:latest-cuda}"
    container_name: "${NAME:-libretranslate-whispher}"
    restart: "${RESTART:-unless-stopped}"

    labels:
      - "com.centurylinklabs.watchtower.enable=true"
      # - "autoheal-app=true"
      # - "autoheal"

    environment:
      - "PUID=${PUID:-1000}"
      - "PGID=${PGID:-1000}"
      - "LT_DISABLE_WEB_UI=${LT_DISABLE_WEB_UI:-True}"
      - "LT_LOAD_ONLY=${LT_LOAD_ONLY:-en,fr,es}"
      - "LT_UPDATE_MODELS=${LT_UPDATE_MODELS:-True}"

    volumes:
      - "/etc/localtime:/etc/localtime:ro"
      - "/etc/timezone:/etc/timezone:ro"
      - "../DATA/libretranslate-whispher/data:/home/libretranslate/.local/share"
      - "../DATA/libretranslate-whispher/cache:/home/libretranslate/.local/cache"

    hostname: "${NAME:-libretranslate-whispher}"

    networks:
      host:
      ai-services:

    ports:
      - "${PORT:-5000}:5000"

    # user: root

    env_file:
      - "./libretranslate-whispher/.env"

    runtime: nvidia
    deploy:
      replicas: 1
      resources:
        # limits:
        #   memory: 1G
        #   cpus: "1.00"
        reservations:
          # memory: 512M
          # cpus: "0.50"
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu, compute, video, graphics, utility]

    tty: true
    
    stdin_open: true

    # Optional: Health check for monitoring
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=3", "--spider", "http://localhost:5000/api/health"]
      interval: "30s"
      timeout: "10s"
      start_period: "30s"
      retries: "3"

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"