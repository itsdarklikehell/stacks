services:
  anythingllm:
    image: ${IMAGE:-mintplexlabs/anythingllm:latest}
    # image: ${IMAGE:-mintplexlabs/anythingllm:render}
    # image: ${IMAGE:-mintplexlabs/anythingllm:railway}
    # image: ${IMAGE:-mintplexlabs/anythingllm:pg}
    container_name: ${NAME:-anythingllm}
    restart: ${RESTART:-unless-stopped}

    labels:
      - com.centurylinklabs.watchtower.enable=true
      # - autoheal-app
      # - autoheal-app=true

    environment:
      - EMBEDDING_BASE_PATH=http://127.0.0.1:11434
      - EMBEDDING_ENGINE=ollama
      - EMBEDDING_MODEL_MAX_CHUNK_LENGTH=8192
      - EMBEDDING_MODEL_PREF=nomic-embed-text:latest
      - JWT_SECRET="make this a large list of random numbers and letters 20+"
      - LLM_PROVIDER=ollama
      - OLLAMA_BASE_PATH=http://127.0.0.1:11434
      - OLLAMA_MODEL_PREF=llama2
      - OLLAMA_MODEL_TOKEN_LIMIT=4096
      - PASSWORDMINCHAR=8
      - COLLECTOR_ALLOW_ANY_IP=true
      - COMMUNITY_HUB_BUNDLE_DOWNLOADS_ENABLED=1
      - PASSWORDLOWERCASE=1
      - PASSWORDMAXCHAR=250
      - PASSWORDMINCHAR=8
      - PASSWORDNUMERIC=1
      - PASSWORDREQUIREMENTS=4
      - PASSWORDSYMBOL=1
      - PASSWORDUPPERCASE=1
      - PGID=${PGID:-1000}
      - PUID=${PUID:-1000}
      - SERVER_PORT=3002
      - STORAGE_DIR=/app/server/storage
      - STORAGE_LOCATION=/app/server/storage
      - TTS_PROVIDER=native
      - TZ=${TZ:-Europe/Amsterdam}
      - VECTOR_DB=lancedb
      - WHISPER_PROVIDER=local
      - AGENT_SEARXNG_API_URL=http://localhost:8081/search?q=<query>

    cap_add:
      - SYS_NICE
      - NET_ADMIN
      - IPC_LOCK

    # command: [--cap-add=SYS_NICE, --cap-add=NET_ADMIN, --cap-add=IPC_LOCK]

    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - anythingllm_storage:/app/server/storage:rw
      - anythingllm_skills:/app/server/storage/plugins/agent-skills:rw
      - anythingllm_hotdir:/app/collector/hotdir:rw
      - anythingllm_outputs:/app/collector/outputs:rw
      - ./anythingllm/.env:/app/server/.env

    hostname: ${NAME:-anythingllm}

    user: ${PUID:-1000}:${PGID:-1000}

    networks:
      host:
      ai-services:

    ports:
      - ${PORT:-3002}:3002

    env_file:
      - ./anythingllm/.env

    runtime: nvidia
    deploy:
      replicas: 1
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    tty: true

    stdin_open: true

    # healthcheck:
    #   test:
    #     [
    #       CMD,
    #       wget,
    #       --no-verbose,
    #       --tries=3,
    #       --spider,
    #       http://localhost:${PORT:-3002}/api/health,
    #     ]
    #   interval: 30s
    #   timeout: 10s
    #   start_period: 30s
    #   retries: 3

    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: 3
