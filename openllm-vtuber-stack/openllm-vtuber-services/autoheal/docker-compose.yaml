services:
  autoheal-openllm-vtuber-services:
    image: "${AUTOHEAL_IMAGE:-willfarrell/autoheal}"
    container_name: "${AUTOHEAL_CONTAINER_NAME:-autoheal-openllm-vtuber-services}"
    restart: "${RESTART:-unless-stopped}"

    labels:
      - "com.centurylinklabs.watchtower.enable=true"
      # - "autoheal-app=true"
      # - "autoheal"

    environment:
      AUTOHEAL_CONTAINER_LABEL: "${AUTOHEAL_CONTAINER_LABEL:-autoheal}"
      AUTOHEAL_START_PERIOD: 0
      AUTOHEAL_INTERVAL: 5
      AUTOHEAL_DEFAULT_STOP_TIMEOUT: 10
      AUTOHEAL_ONLY_MONITOR_RUNNING: true
    # network_mode: "${AUTOHEAL_NETWORK_MODE:-none}"
    # network_mode: "${AUTOHEAL_NETWORK_MODE:-none}"

    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /var/run/docker.sock:/var/run/docker.sock

    hostname: autoheal-openllm-vtuber-services

    # command: [ "ollama", "pull", "qwen3"]

    networks:
      host:
      openllm-vtuber-services:

    # ports:
    #   - "80:80"

    env_file:
      - ./autoheal/.env

    deploy:
      replicas: 1
      # resources:
      #   limits:
      #     memory: 512M
      #     cpus: "0.50"
      #   reservations:
      #     memory: 256M
      #     cpus: "0.25"

    # depends_on:
    #   - faster-whisper-gpu
    #   - wyoming-piper


    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
