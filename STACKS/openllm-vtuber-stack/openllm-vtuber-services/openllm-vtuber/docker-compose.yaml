services:
  openllm-vtuber:
    # image: ${IMAGE:-t41372/open-llm-vtuber}
    image: ${IMAGE:-t41372/open-llm-vtuber:with-bark-and-oai-whisper}
    container_name: ${NAME:-openllm-vtuber}
    restart: ${RESTART:-unless-stopped}

    build:
      context: ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber
      args:
        UID: ${PUID:-1000}
        GID: ${PGID:-1000}
        INSTALL_ORIGINAL_WHISPER: true
        INSTALL_BARK: true
      dockerfile: ./CustomDockerfile-openllm-vtuber-uv
      # dockerfile: ./CustomDockerfile-openllm-vtuber-conda
      # dockerfile: ./CustomDockerfile-openllm-vtuber-venv

    labels:
      - com.centurylinklabs.watchtower.enable=true
      - com.ouroboros.enable=true
      - autoheal-app
      - autoheal-app=true
      - homarr-app=true
      - homarr

    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - TZ=${TZ:-Europe/Amsterdam}

      - OAUTHLIB_RELAX_TOKEN_SCOPE=1
      - DOCKER_MODS=linuxserver/mods:universal-package-install|linuxserver/mods:universal-apprise|linuxserver/mods:universal-cron|linuxserver/mods:universal-internationalization|linuxserver/mods:universal-stdout-logs|lscr.io/linuxserver/mods:universal-unrar6
      # - DOCKER_HOST=
      - INSTALL_PACKAGES=libfuse2|git|gdb
      - RESTART_APP=true

    volumes:
      - /etc/localtime:/etc/localtime:ro
      # - /etc/timezone:/etc/timezone:ro
      - /var/run/docker.sock:/var/run/docker.sock

      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/conf.yaml:/app/conf.yaml
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/avatars:/app/avatars
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/avatars:/app/backgrounds
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/characters:/app/characters
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/chat_history:/app/chat_history
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/live2d-models:/app/live2d-models
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/logs:/app/logs
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/prompts/utils:/app/prompts/utils
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/SCRIPTS:/app/SCRIPTS
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/mcp_servers.json:/app/mcp_servers.json
      - ../../../DATA/openllm-vtuber-stack/Open-LLM-VTuber/model_dict.json:/app/model_dict.json

    hostname: ${NAME:-openllm-vtuber}

    # user: ${PUID:-1000}:${PGID:-1000}

    networks:
      host:
      openllm-vtuber-services:

    ports:
      - ${PORT:-12393}:12393

    env_file:
      - ./openllm-vtuber/.env

    runtime: nvidia
    deploy:
      replicas: 1
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu, compute, video, graphics, utility]

    tty: true

    stdin_open: true

    shm_size: 1gb

    # healthcheck:
    #   test:
    #     [
    #       CMD,
    #       wget,
    #       --no-verbose,
    #       --tries=3,
    #       --spider,
    #       http://localhost:${PORT:-12393}/api/health,
    #     ]
    #   interval: 30s
    #   timeout: 10s
    #   start_period: 30s
    #   retries: 3

    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: 3
