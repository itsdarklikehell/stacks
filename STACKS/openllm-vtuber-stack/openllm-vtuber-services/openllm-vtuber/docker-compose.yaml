services:
  openllm-vtuber:
    container_name: ${NAME:-openllm-vtuber}
    restart: ${RESTART:-unless-stopped}

    build:
      context: ../../../DATA/openllm-vtuber-stack/openllm-vtuber
      dockerfile: Dockerfile
      args:
        UID: ${PUID:-1000}
        GID: ${PGID:-1000}

    privileged: true

    security_opt:
      - seccomp:unconfined

    devices:
      - /dev/video0:/dev/video0
      - /dev/dri:/dev/dri
      - /dev/snd:/dev/snd
      - /dev/bus/usb:/dev/bus/usb

    group_add:
      - audio
      - video

    labels:
      - com.centurylinklabs.watchtower.enable=true
      - com.ouroboros.enable=true
      - autoheal-app
      - autoheal-app=true
      - homarr-app=true
      - homarr

    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - TZ=${TZ:-Europe/Amsterdam}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=gpu,compute,video,graphics,utility
      # Audio integratie voor Webtop
      - PULSE_SERVER=unix:/run/user/${PUID:-1000}/pulse/native
      - AUDIO_IN_ADJ=100
      - AUDIO_OUT_ADJ=100
      # Forceren dat de desktop software-rendering gebruikt.
      # - KASM_VNC_ARG_LIST=--disable-gpu

    volumes:
      - /etc/localtime:/etc/localtime:ro
      # Audio & Hardware integratie
      - /run/user/${PUID:-1000}/pulse:/run/user/${PUID:-1000}/pulse
      - /var/run/dbus:/var/run/dbus
      - /dev/shm:/dev/shm

      # Persistente data
      - openllm-vtuber_avatars:/app/avatars
      - openllm-vtuber_backgrounds:/app/backgrounds
      - openllm-vtuber_chat_history:/app/chat_history
      - openllm-vtuber_characters:/app/characters
      - openllm-vtuber_live2d-models:/app/live2d-models
      - openllm-vtuber_logs:/app/logs
      - openllm-vtuber_prompts:/app/prompts

      # Config files (bind mounts)
      - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/conf.yaml:/app/conf.yaml
      - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/mcp_servers.json:/app/mcp_servers.json
      - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/model_dict.json:/app/model_dict.json


      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/avatars:/app/avatars
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/backgrounds:/app/backgrounds
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/chat_history:/app/chat_history
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/characters:/app/characters
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/live2d-models:/app/live2d-models
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/logs:/app/logs
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/models:/app/models
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/prompts:/app/prompts

    hostname: ${NAME:-openllm-vtuber}

    # user: ${PUID:-1000}:${PGID:-1000}

    networks:
      # host:
      openllm-vtuber-services:

    ports:
      - 5350:3000
      - 5351:3001
      - 12393:12393
      - 3855:9090

    env_file:
      - ./openllm-vtuber/.env

    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu, compute, video, graphics, utility]

    tty: true

    stdin_open: true

    shm_size: 4gb

    # healthcheck:
    #   test:
    #     [
    #       CMD,
    #       wget,
    #       --no-verbose,
    #       --tries=3,
    #       --spider,
    #       http://localhost:${PORT:-12393}/api/health,
    #     ]
    #   interval: 30s
    #   timeout: 10s
    #   start_period: 30s
    #   retries: 3


    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: 3

