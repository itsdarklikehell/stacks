services:
  openllm-vtuber-webtop:
    container_name: ${NAME:-openllm-vtuber-webtop}
    restart: ${RESTART:-unless-stopped}

    build:
      context: ../../../DATA/openllm-vtuber-stack/openllm-vtuber
      dockerfile: Dockerfile-webtop
      # args:
      #   UID: ${PUID:-1000}
      #   GID: ${PGID:-1000}

    labels:
      - com.centurylinklabs.watchtower.enable=true
      - com.ouroboros.enable=true
      - autoheal=true
      - autoheal-app
      - autoheal-app=true
      - homarr-app=true
      - homarr

    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - TZ=${TZ:-Europe/Amsterdam}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video

    volumes:
      - /etc/localtime:/etc/localtime:ro

      # Persistente data
      - openllm-vtuber_avatars:/app/avatars
      - openllm-vtuber_backgrounds:/app/backgrounds
      - openllm-vtuber_chat_history:/app/chat_history
      - openllm-vtuber_characters:/app/characters
      - openllm-vtuber_live2d-models:/app/live2d-models
      - openllm-vtuber_logs:/app/logs
      - openllm-vtuber_prompts:/app/prompts

      # Config files (bind mounts)
      - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/conf.yaml:/app/conf.yaml
      - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/mcp_servers.json:/app/mcp_servers.json
      - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/model_dict.json:/app/model_dict.json

      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/avatars:/app/avatars
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/backgrounds:/app/backgrounds
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/chat_history:/app/chat_history
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/characters:/app/characters
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/live2d-models:/app/live2d-models
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/logs:/app/logs
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/models:/app/models
      # - ../../../DATA/openllm-vtuber-stack/openllm-vtuber/prompts:/app/prompts

    hostname: ${NAME:-openllm-vtuber-webtop}

    # user: ${PUID:-1000}:${PGID:-1000}

    networks:
      host:
      openllm-vtuber-services:
      ai-services:

    ports:
      - 12394:12393
      - 5527:3000
      - 5528:3001

    env_file:
      - ./openllm-vtuber-webtop/.env

    # Gebruik de NVIDIA runtime voor AI-versnelling
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu, compute, video, utility]

    tty: true

    stdin_open: true

    shm_size: 2gb

    # healthcheck:
    #   test:
    #     [
    #       CMD,
    #       wget,
    #       --no-verbose,
    #       --tries=3,
    #       --spider,
    #       http://localhost:${PORT:-12393}/api/health,
    #     ]
    #   interval: 30s
    #   timeout: 10s
    #   start_period: 30s
    #   retries: 3

    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: 3

